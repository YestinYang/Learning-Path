{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WeRateDogs Twitter Data Wrangling\n",
    "\n",
    "This project is to gather the data from [WeRateDogs (@dog_rates)](https://twitter.com/dog_rates), then assess and clean the data for further exploratory data analysis, and also training a recurrent neural network to identify the species of dogs.\n",
    "\n",
    "The project focuses on below targets:\n",
    "1. Keep the original ranks from WeRateDogs only, not the ones from retweet \n",
    "2. At least 8 quality issues and 2 tidiness issues\n",
    "3. Including merge data table to achieve tidiness target\n",
    "4. Be noticed that numerator sometimes is larger than denominator in this dataset, and that is the way WeRateDogs runs\n",
    "\n",
    "The process of this project is as below:\n",
    "1. Data wrangling, including cleaning, assessing and cleaning in programmatic ways\n",
    "2. Store, analyze and visualize the processed data\n",
    "3. Summary the first two steps in a report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import tweepy\n",
    "import json\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering\n",
    "\n",
    "There are three files to be gathered:\n",
    "1. Download twitter data of WeRateDogs from [GitHub repo](https://github.com/udacity/new-dand-advanced-china/tree/master/数据清洗/WeRateDogs项目)\n",
    "2. Download programmatically for the image recognition result of dog species, in above repo\n",
    "3. Gather retweet_count and favorite_count via `Tweepy` API, and combine them into a JSON format txt file, each line representing a single record, at least including `tweet ID`, `retweet_count` and `favorite_count` information \n",
    "\n",
    "After gathering, import all into separated `pandas.DataFrame` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2356 entries, 0 to 2355\n",
      "Data columns (total 17 columns):\n",
      "tweet_id                      2356 non-null int64\n",
      "in_reply_to_status_id         78 non-null float64\n",
      "in_reply_to_user_id           78 non-null float64\n",
      "timestamp                     2356 non-null object\n",
      "source                        2356 non-null object\n",
      "text                          2356 non-null object\n",
      "retweeted_status_id           181 non-null float64\n",
      "retweeted_status_user_id      181 non-null float64\n",
      "retweeted_status_timestamp    181 non-null object\n",
      "expanded_urls                 2297 non-null object\n",
      "rating_numerator              2356 non-null int64\n",
      "rating_denominator            2356 non-null int64\n",
      "name                          2356 non-null object\n",
      "doggo                         2356 non-null object\n",
      "floofer                       2356 non-null object\n",
      "pupper                        2356 non-null object\n",
      "puppo                         2356 non-null object\n",
      "dtypes: float64(4), int64(3), object(10)\n",
      "memory usage: 313.0+ KB\n"
     ]
    }
   ],
   "source": [
    "##### 1. Import existed dataset, including tweet ID #####\n",
    "twitter_archive_enhanced = pd.read_csv('twitter-archive-enhanced.csv')\n",
    "twitter_archive_enhanced.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2075 entries, 0 to 2074\n",
      "Data columns (total 12 columns):\n",
      "tweet_id    2075 non-null int64\n",
      "jpg_url     2075 non-null object\n",
      "img_num     2075 non-null int64\n",
      "p1          2075 non-null object\n",
      "p1_conf     2075 non-null float64\n",
      "p1_dog      2075 non-null bool\n",
      "p2          2075 non-null object\n",
      "p2_conf     2075 non-null float64\n",
      "p2_dog      2075 non-null bool\n",
      "p3          2075 non-null object\n",
      "p3_conf     2075 non-null float64\n",
      "p3_dog      2075 non-null bool\n",
      "dtypes: bool(3), float64(3), int64(2), object(4)\n",
      "memory usage: 152.1+ KB\n"
     ]
    }
   ],
   "source": [
    "##### 2. Programmatically download image recoginition result ######\n",
    "image_predictions = pd.read_csv('https://raw.githubusercontent.com/udacity/new-dand-advanced-china/master/%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/WeRateDogs%E9%A1%B9%E7%9B%AE/image-predictions.tsv',\n",
    "                               sep='\\t')\n",
    "image_predictions.to_csv('image-predictions.tsv')\n",
    "image_predictions.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 3. Info from Twitter API via tweepy #####\n",
    "### Create tweepy instance for Twitter API ###\n",
    "# consumer_key = ''\n",
    "# consumer_secret = ''\n",
    "# access_token = ''\n",
    "# access_token_secret = ''\n",
    "\n",
    "# auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "# auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "# api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Looping to download all info and store in a list instance ###\n",
    "# tweet_json = []\n",
    "# tweet_error = {}\n",
    "# for tweet_id in twitter_archive_enhanced.tweet_id:\n",
    "#     try:\n",
    "#         tweet = api.get_status(tweet_id, tweet_mode='extended')\n",
    "#         tweet_json.append(tweet._json)\n",
    "#     except Exception as e:\n",
    "#         tweet_error[tweet_id] = e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Re-download the error part ###\n",
    "# tweet_error_2nd = {}\n",
    "# for tweet_id in tweet_error.keys():\n",
    "#     try:\n",
    "#         tweet = api.get_status(tweet_id, tweet_mode='extended')\n",
    "#         tweet_json.append(tweet._json)\n",
    "#     except Exception as e:\n",
    "#         tweet_error_2nd[tweet_id] = e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet_error_2nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### From above, there are 11 tweet_id are unable to find corresponding info ###\n",
    "### Re-download the last one ###\n",
    "# tweet = api.get_status('704761120771465216', tweet_mode='extended')\n",
    "# tweet_json.append(tweet._json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Store result in txt file ###\n",
    "# with open('tweet_json_YY.txt', 'w') as output:  \n",
    "#     for i in range(len(tweet_json)):\n",
    "#         json.dump(tweet_json[i], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import tweet_json.txt to pandas.DataFrame ###\n",
    "# Only include tweet ID, retweet_count and favorite_count #\n",
    "json_str = []\n",
    "with open('tweet_json.txt', encoding='utf-8') as json_file:\n",
    "    for i in range(2352):   # there are 2352 rows in txt file got from visual inspection\n",
    "        tweet = json_file.readline()\n",
    "        json_str.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform string read from txt to dic, and store in list to create DataFrame #\n",
    "json_list = []\n",
    "for i in range(len(json_str)):\n",
    "    json_list.append(json.loads(json_str[i]))\n",
    "\n",
    "tweet_json = pd.DataFrame(json_list)[['id', 'retweet_count', 'favorite_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2352 entries, 0 to 2351\n",
      "Data columns (total 3 columns):\n",
      "id                2352 non-null int64\n",
      "retweet_count     2352 non-null int64\n",
      "favorite_count    2352 non-null int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 55.2 KB\n"
     ]
    }
   ],
   "source": [
    "tweet_json.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Data Collection\n",
    "\n",
    "Corresponding to three targets,\n",
    "1. Existed file was loaded via `pandas.read_csv` from local path, storing as `twitter_archive_enhanced` dataframe\n",
    "2. Image recognition result was downloaded via `pandas.read_csv` from url, storing as `image_predictions` dataframe\n",
    "3. Tweet info downloaded via tweepy was stored in `tweet_json_YY.txt`, to be distinguishable from the provided `tweet_json.txt` . However, to be eaiser for project reivew, `tweet_json.txt` was still used to generate `tweet_json` dataframe for the rest of project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Assessing\n",
    "\n",
    "Accomplish at least 8 quality issues and 2 tidiness issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id                        int64\n",
       "in_reply_to_status_id         float64\n",
       "in_reply_to_user_id           float64\n",
       "timestamp                      object\n",
       "source                         object\n",
       "text                           object\n",
       "retweeted_status_id           float64\n",
       "retweeted_status_user_id      float64\n",
       "retweeted_status_timestamp     object\n",
       "expanded_urls                  object\n",
       "rating_numerator                int64\n",
       "rating_denominator              int64\n",
       "name                           object\n",
       "doggo                          object\n",
       "floofer                        object\n",
       "pupper                         object\n",
       "puppo                          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_archive_enhanced.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of items in a cell is 8\n"
     ]
    }
   ],
   "source": [
    "##### Check the max number of items in expanded_urls #####\n",
    "urls_split = twitter_archive_enhanced.expanded_urls.str.strip().str.split(',')\n",
    "\n",
    "url_count = 1\n",
    "missing_cell = []\n",
    "for i in range(len(urls_split)):\n",
    "    try:\n",
    "        if len(urls_split[i])>url_count:\n",
    "            url_count = len(urls_split[i])\n",
    "    except Exception as e:\n",
    "        missing_cell.append(i)\n",
    "print ('Max number of items in a cell is ' + str(url_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality\n",
    "#### Table `twitter_archive_enhanced` \n",
    "- we only consider the tweets with original rates and pictures, replies, retweets and tweets without pictures should be removed\n",
    "- column `source` is recored as html element but the useful part is only the content *(Validity)*\n",
    "- column `name` has 55 values equaling to 'a', and another words like 'an', 'actually' etc, but actually there is no dog names in text *(Validity)*\n",
    "- column `rating_denominator` has cell not equaling to 10. Some are due to multiple dogs in the picture, and some are due to wrong extraction from text. *(Validity and Consistency)*\n",
    "- columns `timestamp` have '+0000' after all time but meaningless\n",
    "- columns `timestamp` should be datetime dtype\n",
    "- all 'None' values should be set as missing values using NaN\n",
    "\n",
    "#### Table `image_predictions` \n",
    "- columns `p1`, `p2`, `p3` have cells starting with either upper case or lower case letter *(Consistency)*\n",
    "\n",
    "### Tidiness\n",
    "- (`twitter_archive_enhanced`) column `expanded_urls` has some cells with twitter urls and external urls, or duplicated urls\n",
    "- (`twitter_archive_enhanced`) columns `doggo`, `floofer`, `pupper` and `puppo` is actually one variable\n",
    "- table `tweet_json` and `image_predictions` are parts of `twitter_archive_enhanced` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Accomplish at least 8 quality issues and 2 tidiness issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Copy original data to be cleaned ######\n",
    "twitter_archive_enhanced_clean = twitter_archive_enhanced.copy()\n",
    "image_predictions_claen = image_predictions.copy()\n",
    "tweet_json_clean = tweet_json.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no completeness issues, so start with tidiness issues.\n",
    "\n",
    "### Tidiness\n",
    "\n",
    "#### 1. (twitter_archive_enhanced) column `expanded_urls` has some cells with twitter urls and external urls, or duplicated urls\n",
    "\n",
    "##### Define 1\n",
    "1. Split urls by comma, remove duplicated urls\n",
    "2. Filter out twitter urls and outter urls into separated columns\n",
    "\n",
    "##### Code 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of items in a cell is 2\n"
     ]
    }
   ],
   "source": [
    "### Split out urls as items in list ###\n",
    "urls_split = twitter_archive_enhanced_clean.expanded_urls.str.strip().str.split(',')\n",
    "\n",
    "### Remove duplicated urls ###\n",
    "missing_cell = []\n",
    "for i in range(len(urls_split)):\n",
    "    try:\n",
    "        urls_split[i] = list(set(urls_split[i]))\n",
    "    except Exception as e:\n",
    "        missing_cell.append(i)\n",
    "        \n",
    "##### Check the max number of items in expanded_urls after cleaning #####\n",
    "url_count = 1\n",
    "missing_cell = []\n",
    "for i in range(len(urls_split)):\n",
    "    try:\n",
    "        if len(urls_split[i])>url_count:\n",
    "            url_count = len(urls_split[i])\n",
    "    except Exception as e:\n",
    "        missing_cell.append(i)\n",
    "print ('Max number of items in a cell is ' + str(url_count))\n",
    "\n",
    "##### Split out twitter url and outter url #####\n",
    "regex = re.compile(r'https://twitter.*')\n",
    "twitter_urls = []\n",
    "outter_urls = []\n",
    "\n",
    "for i in range(len(urls_split)):\n",
    "    \n",
    "    if urls_split[i] != urls_split[i]:\n",
    "        twitter_urls.append(np.nan)\n",
    "        outter_urls.append(np.nan)\n",
    "    \n",
    "    elif list(filter(regex.match, urls_split[i])):\n",
    "        t_url = list(filter(regex.match, urls_split[i]))\n",
    "        twitter_urls.append(t_url[0])\n",
    "        outter_urls.append(np.nan)\n",
    "    else:\n",
    "        twitter_urls.append(np.nan)\n",
    "        outter_urls.append(urls_split[i][0])\n",
    "\n",
    "### Generate new columns and append on original dataframe ###\n",
    "clean_url_dict = {'twitter_urls': twitter_urls,\n",
    "                  'outter_urls': outter_urls}\n",
    "clean_urls = pd.DataFrame(clean_url_dict)\n",
    "\n",
    "### Drop original column and merge new columns to twitter_archive_enhanced_clean ###\n",
    "twitter_archive_enhanced_clean.drop('expanded_urls', axis=1, inplace=True)\n",
    "twitter_archive_enhanced_clean = pd.concat([twitter_archive_enhanced_clean, clean_urls], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    https://twitter.com/dog_rates/status/892420643...\n",
       "1    https://twitter.com/dog_rates/status/892177421...\n",
       "2    https://twitter.com/dog_rates/status/891815181...\n",
       "3    https://twitter.com/dog_rates/status/891689557...\n",
       "4    https://twitter.com/dog_rates/status/891327558...\n",
       "Name: twitter_urls, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_archive_enhanced_clean.twitter_urls.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308                              NaN\n",
       "309                              NaN\n",
       "310    https://vine.co/v/5W2Dg3XPX7a\n",
       "311                              NaN\n",
       "312                              NaN\n",
       "Name: outter_urls, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_notnull = twitter_archive_enhanced_clean.outter_urls.first_valid_index()\n",
    "twitter_archive_enhanced_clean.outter_urls.iloc[first_notnull-2:first_notnull+3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "#### 2. (twitter_archive_enhanced) columns doggo, floofer, pupper and puppo is actually one variable\n",
    "\n",
    "##### Define 2\n",
    "\n",
    "1. Combine four stage columns\n",
    "2. Manual update cell with multiple stage info by understanding each tweet\n",
    "\n",
    "##### Code 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Combine four stage columns into one list #####\n",
    "stage = twitter_archive_enhanced_clean[['doggo', 'floofer', 'pupper', 'puppo']]\n",
    "\n",
    "dogs_list = []\n",
    "for i in range(len(twitter_archive_enhanced_clean)):\n",
    "    dogs = list(set(stage.iloc[i].values))\n",
    "    if len(dogs)>1:\n",
    "        dogs.remove('None')\n",
    "    dogs_list.append(dogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum length of single cell: 2\n"
     ]
    }
   ],
   "source": [
    "##### Manual handle cell with double dogs #####\n",
    "### Return a index list of cell with double dogs ###\n",
    "multi_dogs = []\n",
    "length = 1\n",
    "for i in range(len(dogs_list)):\n",
    "    if len(dogs_list[i])>1:\n",
    "        multi_dogs.append(i)\n",
    "        if len(dogs_list[i])>length:\n",
    "            length = len(dogs_list[i])\n",
    "print ('Maximum length of single cell: '+str(length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read tweets and understand their real meaning ###\n",
    "dogs_list[multi_dogs[0]] = ['puppo']  # 191\n",
    "dogs_list[multi_dogs[1]] = ['floofer']  # 200\n",
    "dogs_list[multi_dogs[2]] = ['pupper']  # 460\n",
    "dogs_list[multi_dogs[3]] = dogs_list[multi_dogs[3]]  # two dogs in pic 531\n",
    "dogs_list[multi_dogs[4]] = dogs_list[multi_dogs[4]]  # two dogs in pic 565\n",
    "dogs_list[multi_dogs[5]] = ['pupper']  # 575\n",
    "dogs_list[multi_dogs[6]] = ['doggo']  # 705\n",
    "dogs_list[multi_dogs[7]] = dogs_list[multi_dogs[7]]  # two dogs in pic 733\n",
    "dogs_list[multi_dogs[8]] = dogs_list[multi_dogs[8]]  # two dogs in pic 778 RT\n",
    "dogs_list[multi_dogs[9]] = dogs_list[multi_dogs[9]]  # two dogs in pic 822 RT\n",
    "dogs_list[multi_dogs[10]] = dogs_list[multi_dogs[10]]  # two dogs in pic 889\n",
    "dogs_list[multi_dogs[11]] = ['None']  # 956\n",
    "dogs_list[multi_dogs[12]] = dogs_list[multi_dogs[12]]  # two dogs in pic 1063\n",
    "dogs_list[multi_dogs[13]] = dogs_list[multi_dogs[13]]  # two dogs in pic 1113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Create new columns and update original DataFrame ######\n",
    "dogs_dict = {'dog_stage': list(\",\".join(map(str,i)) for i in dogs_list)}\n",
    "dog_stage = pd.DataFrame(dogs_dict)\n",
    "twitter_archive_enhanced_clean.drop(['doggo', 'floofer', 'pupper', 'puppo'], axis=1, inplace=True)\n",
    "twitter_archive_enhanced_clean = pd.concat([twitter_archive_enhanced_clean, dog_stage], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10     None\n",
       "11     None\n",
       "12    puppo\n",
       "13     None\n",
       "14    puppo\n",
       "15     None\n",
       "Name: dog_stage, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_archive_enhanced_clean.dog_stage.iloc[10:16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "#### 3. table `tweet_json` and `image_predictions` are parts of `twitter_archive_enhanced`\n",
    "\n",
    "##### Define 3\n",
    "\n",
    "1. Join `retweet_count` and `favorite_count` from `tweet_json` to `twitter_archive_enhanced`\n",
    "2. Join dog species with highest probability of prediciton from `image_predicitons` to `twitter_archive_enhanced`\n",
    "\n",
    "##### Code 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Join with tweet_json #####\n",
    "twitter_archive_enhanced_clean = pd.merge(twitter_archive_enhanced_clean,\n",
    "                                          tweet_json,\n",
    "                                          left_on='tweet_id', right_on='id',\n",
    "                                          how='left')\n",
    "twitter_archive_enhanced_clean.drop(['id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Join with image_prediction #####\n",
    "### Select out highest prob dog prediction ###\n",
    "tweet_id = []\n",
    "species_list = []\n",
    "species_prob_list = []\n",
    "\n",
    "for i in range(len(image_predictions)):\n",
    "    \n",
    "    tweet_id.append(image_predictions.tweet_id[i])\n",
    "    \n",
    "    if image_predictions.p1_dog[i]==True:\n",
    "        species_list.append(image_predictions.p1[i])\n",
    "        species_prob_list.append(image_predictions.p1_conf[i])\n",
    "    \n",
    "    elif image_predictions.p2_dog[i]==True:\n",
    "        species_list.append(image_predictions.p2[i])\n",
    "        species_prob_list.append(image_predictions.p2_conf[i])\n",
    "    \n",
    "    elif image_predictions.p3_dog[i]==True:\n",
    "        species_list.append(image_predictions.p3[i])\n",
    "        species_prob_list.append(image_predictions.p3_conf[i])\n",
    "    \n",
    "    else:\n",
    "        species_list.append(np.nan)\n",
    "        species_prob_list.append(np.nan)\n",
    "        \n",
    "### Create DataFrame and join ###\n",
    "image_pred_dict = {'tweet_id': tweet_id,\n",
    "                   'species': species_list,\n",
    "                   'species_prob': species_prob_list}\n",
    "image_pred = pd.DataFrame(image_pred_dict)\n",
    "twitter_archive_enhanced_clean = pd.merge(twitter_archive_enhanced_clean,\n",
    "                                          image_pred,\n",
    "                                          left_on='tweet_id', right_on='tweet_id',\n",
    "                                          how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   NaN\n",
       "1             Chihuahua\n",
       "2             Chihuahua\n",
       "3    Labrador_retriever\n",
       "4                basset\n",
       "Name: species, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_archive_enhanced_clean.species.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         NaN\n",
       "1    0.323581\n",
       "2    0.716012\n",
       "3    0.168086\n",
       "4    0.555712\n",
       "Name: species_prob, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_archive_enhanced_clean.species_prob.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Quality on Table `twitter_archive_enhanced`\n",
    "\n",
    "#### 1. Only consider the tweets with original rates and pictures\n",
    "\n",
    "Replies, retweets and tweets without pictures should be removed.\n",
    "\n",
    "##### Define 1\n",
    "1. remove rows with not null in `in_reply_to_status_id` \n",
    "2. remove rows with not null in `retweeted_status_id`\n",
    "3. remove rows with null in `twitter_urls` and `outter_urls` (`expanded_urls` in original table)\n",
    "4. remove `in_reply_to_status_id`, `in_reply_to_user_id`, `retweeted_status_id`, `retweeted_status_user_id` and `retweeted_status_timestamp` columns\n",
    "\n",
    "##### Code 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Remove reply tweets #####\n",
    "mask_reply = twitter_archive_enhanced_clean.in_reply_to_status_id.notnull()\n",
    "twitter_archive_enhanced_clean.drop(twitter_archive_enhanced_clean[mask_reply].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Remove retweet #####\n",
    "mask_retweet = twitter_archive_enhanced_clean.retweeted_status_id.notnull()\n",
    "twitter_archive_enhanced_clean.drop(twitter_archive_enhanced_clean[mask_retweet].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Remove tweets without image #####\n",
    "mask_image = (twitter_archive_enhanced_clean.twitter_urls.isnull()) & (twitter_archive_enhanced_clean.outter_urls.isnull())\n",
    "twitter_archive_enhanced_clean.drop(twitter_archive_enhanced_clean[mask_image].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Remove reply and retweet related columns #####\n",
    "twitter_archive_enhanced_clean.drop(['in_reply_to_status_id',\n",
    "                                     'in_reply_to_user_id',\n",
    "                                     'retweeted_status_id',\n",
    "                                     'retweeted_status_user_id',\n",
    "                                     'retweeted_status_timestamp'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet_id', 'timestamp', 'source', 'text', 'rating_numerator',\n",
       "       'rating_denominator', 'name', 'outter_urls', 'twitter_urls',\n",
       "       'dog_stage', 'retweet_count', 'favorite_count', 'species',\n",
       "       'species_prob'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Check remaining columns #####\n",
    "twitter_archive_enhanced_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Check whether there is tweet without image or video #####\n",
    "((twitter_archive_enhanced_clean.twitter_urls.isnull()) & (twitter_archive_enhanced_clean.outter_urls.isnull())).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "#### 2. Column `source` is recored as html element but the useful part is only the content *(Validity)*\n",
    "\n",
    "##### Define 2\n",
    "Use regex to filter out the content from html element, and replace the original value in cell\n",
    "\n",
    "##### Code 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Filter with regex #####\n",
    "regex = re.compile(r'[TV][^\\<]*')\n",
    "source_list = []\n",
    "\n",
    "for i in twitter_archive_enhanced_clean.index:\n",
    "    matches = regex.findall(twitter_archive_enhanced_clean.source[i])\n",
    "    source_list.append(matches[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Create DataFrame and join #####\n",
    "source_dict = {'source': source_list}\n",
    "source_clean = pd.DataFrame(source_dict, index=twitter_archive_enhanced_clean.index)\n",
    "twitter_archive_enhanced_clean.drop('source', axis=1, inplace=True)\n",
    "twitter_archive_enhanced_clean = pd.merge(twitter_archive_enhanced_clean,\n",
    "                                          source_clean,\n",
    "                                          left_index=True, right_index=True,\n",
    "                                          how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Twitter for iPhone     1962\n",
       "Vine - Make a Scene      91\n",
       "Twitter Web Client       30\n",
       "TweetDeck                11\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_archive_enhanced_clean.source.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "#### 3. Column `name` has values which are not names *(Validity)*\n",
    "\n",
    "Column `name` has 55 values equaling to 'a', and another words like 'an', 'actually' etc, but actually there is no dog names in text.\n",
    "\n",
    "##### Define 3\n",
    "1. Detect value starting with lowercase and None using regex\n",
    "2. Replace with `np.nan`\n",
    "\n",
    "##### Code 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Detect and replace non-dog names with regex #####\n",
    "twitter_archive_enhanced_clean.name.replace(r'\\b[a-z][a-z]*|None', np.nan, regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Charlie    11\n",
       "Lucy       11\n",
       "Cooper     10\n",
       "Oliver     10\n",
       "Penny       9\n",
       "Name: name, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_archive_enhanced_clean.name.value_counts().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "#### 4. Column `rating_denominator` has cell not equaling to 10\n",
    "\n",
    "Some are due to multiple dogs in the picture, and some are due to wrong extraction from text. (Validity and Consistency)\n",
    "\n",
    "##### Define 4\n",
    "1. Manually handle 4 rows with denominator not a multiple of 10\n",
    "2. Create a column indicating the number of dogs in tweet image, by dividing denominator by 10\n",
    "3. Create a column indicating the average rating of dogs in each tweet, by dividing numerator by the number of dogs\n",
    "4. Remove numerator and denominator columns\n",
    "\n",
    "##### Code 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Manually handle 4 rows with denominator equalling 2,7,11 #####\n",
    "handle_ind = twitter_archive_enhanced_clean[twitter_archive_enhanced_clean.rating_denominator%10 != 0].index\n",
    "### 1st row ###\n",
    "twitter_archive_enhanced_clean.drop(handle_ind[0], inplace=True)  # no rating, remove row\n",
    "### 2nd row ###\n",
    "twitter_archive_enhanced_clean.rating_numerator.at[handle_ind[1]] = 14\n",
    "twitter_archive_enhanced_clean.rating_denominator.at[handle_ind[1]] = 10\n",
    "### 3rd row ###\n",
    "twitter_archive_enhanced_clean.rating_numerator.at[handle_ind[2]] = 10\n",
    "twitter_archive_enhanced_clean.rating_denominator.at[handle_ind[2]] = 10\n",
    "# ### 4th row ###\n",
    "twitter_archive_enhanced_clean.rating_numerator.at[handle_ind[3]] = 9\n",
    "twitter_archive_enhanced_clean.rating_denominator.at[handle_ind[3]] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Create column for the number of dogs #####\n",
    "twitter_archive_enhanced_clean['num_of_dog'] = twitter_archive_enhanced_clean.rating_denominator/10\n",
    "twitter_archive_enhanced_clean.num_of_dog = twitter_archive_enhanced_clean.num_of_dog.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Create column for average rating of dogs #####\n",
    "twitter_archive_enhanced_clean['avg_rating'] = (twitter_archive_enhanced_clean.rating_numerator\n",
    "                                                / twitter_archive_enhanced_clean.num_of_dog)\n",
    "twitter_archive_enhanced_clean.avg_rating = twitter_archive_enhanced_clean.avg_rating.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Remove numerator and denominator columns #####\n",
    "twitter_archive_enhanced_clean.drop(['rating_numerator', 'rating_denominator'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet_id', 'timestamp', 'text', 'name', 'outter_urls', 'twitter_urls',\n",
       "       'dog_stage', 'retweet_count', 'favorite_count', 'species',\n",
       "       'species_prob', 'source', 'num_of_dog', 'avg_rating'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_archive_enhanced_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     2080\n",
       "5        3\n",
       "8        2\n",
       "17       1\n",
       "15       1\n",
       "Name: num_of_dog, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_archive_enhanced_clean.num_of_dog.value_counts().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12    489\n",
       "10    437\n",
       "11    418\n",
       "13    287\n",
       "9     154\n",
       "Name: avg_rating, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_archive_enhanced_clean.avg_rating.value_counts().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "#### 5. Columns `timestamp` have '+0000' after all time\n",
    "\n",
    "Columns `timestamp` have '+0000' after all time but meaningless.\n",
    "\n",
    "##### Define 5\n",
    "1. Remove '+0000'\n",
    "\n",
    "##### Code 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Remove '+0000' by replacing it with nothing #####\n",
    "twitter_archive_enhanced_clean.timestamp.replace(r'\\s\\+0000', '', regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2017-08-01 16:23:56\n",
       "1    2017-08-01 00:17:27\n",
       "2    2017-07-31 00:18:03\n",
       "3    2017-07-30 15:58:51\n",
       "4    2017-07-29 16:00:24\n",
       "Name: timestamp, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_archive_enhanced_clean.timestamp.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "#### 6. Columns `timestamp` should be datetime dtype\n",
    "\n",
    "##### Define 6\n",
    "1. Convert `timestamp` to datetime dtype\n",
    "\n",
    "##### Code 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_enhanced_clean.timestamp = pd.to_datetime(twitter_archive_enhanced_clean.timestamp,\n",
    "                                                          errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<M8[ns]')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_archive_enhanced_clean.timestamp.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_archive_enhanced_clean.timestamp.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "#### 7. All 'None' values should be set as missing values using NaN\n",
    "\n",
    "##### Define 7\n",
    "1. replace 'None' values with np.nan\n",
    "\n",
    "##### Code 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_enhanced_clean.replace('None', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id          0\n",
       "timestamp         0\n",
       "text              0\n",
       "name              0\n",
       "outter_urls       0\n",
       "twitter_urls      0\n",
       "dog_stage         0\n",
       "retweet_count     0\n",
       "favorite_count    0\n",
       "species           0\n",
       "species_prob      0\n",
       "source            0\n",
       "num_of_dog        0\n",
       "avg_rating        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(twitter_archive_enhanced_clean=='None').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Quality on Table `image_predictions`\n",
    "\n",
    "#### 8. Columns p1, p2, p3 have cells starting with either upper case or lower case letter (Consistency)\n",
    "\n",
    "Since table `image_predictions` was joint with table `twitter_archive_enhanced`, we only consider update column `species`.\n",
    "\n",
    "##### Define 8\n",
    "\n",
    "Uppercase the first letter of each value.\n",
    "\n",
    "##### Code 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_enhanced_clean.species = twitter_archive_enhanced_clean.species.str.capitalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "regex = re.compile(r'^[a-z]')\n",
    "start_lower = []\n",
    "error = []\n",
    "for i in twitter_archive_enhanced_clean.species:\n",
    "    try:\n",
    "        matches = regex.findall(i)\n",
    "        if len(matches) != 0:\n",
    "            start_lower.append(i)\n",
    "    except Exception as e:\n",
    "        error.append(e)\n",
    "print (start_lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Storage and Visualization\n",
    "\n",
    "1. Store the processed data as `twitter_archive_master.csv`\n",
    "2. Illustrate at least 3 intuitions from data analysis and 1 visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Store the processed master table #####\n",
    "twitter_archive_enhanced_clean.to_csv('twitter_archive_master.csv')\n",
    "twitter_archive_master = twitter_archive_enhanced_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_timestamp = pd.DataFrame(twitter_archive_master.timestamp.apply(lambda x: x.strftime('%Y-%m')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Count of Tweets by Date')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a22199780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##### Visualization #####\n",
    "### Distribution of the number of tweets by time ###\n",
    "date = np.sort(twitter_archive_master.timestamp.apply(lambda x: x.strftime('%Y-%m')).unique())\n",
    "\n",
    "g = sns.factorplot(x='timestamp', data=date_timestamp, kind=\"count\",\n",
    "                   palette=\"RdBu_r\", size=8, aspect=1.5, order=date)\n",
    "g.set_xticklabels(step=2)\n",
    "g.set_xlabels(label='Tweet Date')\n",
    "g.set_ylabels(label='Count of Tweets')\n",
    "plt.title('Count of Tweets by Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Favorite and retweet counts by species ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Device type (source) of tweeting by time ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sumamry Report\n",
    "\n",
    "1. 300-to-600-word report for internal assessment to complete project, about how the whole project was done, saved as `wrangle_report.pdf` \n",
    "2. ~250-word report for external demonstration like blog post, saved as `act_report.pdf` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
