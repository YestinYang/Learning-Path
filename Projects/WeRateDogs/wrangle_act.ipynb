{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WeRateDogs Twitter Data Wrangling\n",
    "\n",
    "This project is to gather the data from [WeRateDogs (@dog_rates)](https://twitter.com/dog_rates), then assess and clean the data for further exploratory data analysis, and also training a recurrent neural network to identify the species of dogs.\n",
    "\n",
    "The project focuses on below targets:\n",
    "1. Keep the original ranks from WeRateDogs only, not the ones from retweet \n",
    "2. At least 8 quality issues and 2 tidiness issues\n",
    "3. Including merge data table to achieve tidiness target\n",
    "4. Be noticed that numerator sometimes is larger than denominator in this dataset, and that is the way WeRateDogs runs\n",
    "\n",
    "The process of this project is as below:\n",
    "1. Data wrangling, including cleaning, assessing and cleaning in programmatic ways\n",
    "2. Store, analyze and visualize the processed data\n",
    "3. Summary the first two steps in a report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import tweepy\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering\n",
    "\n",
    "There are three files to be gathered:\n",
    "1. Download twitter data of WeRateDogs from [GitHub repo](https://github.com/udacity/new-dand-advanced-china/tree/master/数据清洗/WeRateDogs项目)\n",
    "2. Download programmatically for the image recognition result of dog species, in above repo\n",
    "3. Gather retweet_count and favorite_count via `Tweepy` API, and combine them into a JSON format txt file, each line representing a single record, at least including `tweet ID`, `retweet_count` and `favorite_count` information \n",
    "\n",
    "After gathering, import all into separated `pandas.DataFrame` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2356 entries, 0 to 2355\n",
      "Data columns (total 17 columns):\n",
      "tweet_id                      2356 non-null int64\n",
      "in_reply_to_status_id         78 non-null float64\n",
      "in_reply_to_user_id           78 non-null float64\n",
      "timestamp                     2356 non-null object\n",
      "source                        2356 non-null object\n",
      "text                          2356 non-null object\n",
      "retweeted_status_id           181 non-null float64\n",
      "retweeted_status_user_id      181 non-null float64\n",
      "retweeted_status_timestamp    181 non-null object\n",
      "expanded_urls                 2297 non-null object\n",
      "rating_numerator              2356 non-null int64\n",
      "rating_denominator            2356 non-null int64\n",
      "name                          2356 non-null object\n",
      "doggo                         2356 non-null object\n",
      "floofer                       2356 non-null object\n",
      "pupper                        2356 non-null object\n",
      "puppo                         2356 non-null object\n",
      "dtypes: float64(4), int64(3), object(10)\n",
      "memory usage: 313.0+ KB\n"
     ]
    }
   ],
   "source": [
    "##### 1. Import existed dataset, including tweet ID #####\n",
    "twitter_archive_enhanced = pd.read_csv('twitter-archive-enhanced.csv')\n",
    "twitter_archive_enhanced.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2075 entries, 0 to 2074\n",
      "Data columns (total 12 columns):\n",
      "tweet_id    2075 non-null int64\n",
      "jpg_url     2075 non-null object\n",
      "img_num     2075 non-null int64\n",
      "p1          2075 non-null object\n",
      "p1_conf     2075 non-null float64\n",
      "p1_dog      2075 non-null bool\n",
      "p2          2075 non-null object\n",
      "p2_conf     2075 non-null float64\n",
      "p2_dog      2075 non-null bool\n",
      "p3          2075 non-null object\n",
      "p3_conf     2075 non-null float64\n",
      "p3_dog      2075 non-null bool\n",
      "dtypes: bool(3), float64(3), int64(2), object(4)\n",
      "memory usage: 152.1+ KB\n"
     ]
    }
   ],
   "source": [
    "##### 2. Programmatically download image recoginition result ######\n",
    "image_predictions = pd.read_csv('https://raw.githubusercontent.com/udacity/new-dand-advanced-china/master/%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/WeRateDogs%E9%A1%B9%E7%9B%AE/image-predictions.tsv',\n",
    "                               sep='\\t')\n",
    "image_predictions.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 3. Info from Twitter API via tweepy #####\n",
    "### Create tweepy instance for Twitter API ###\n",
    "consumer_key = ''\n",
    "consumer_secret = ''\n",
    "access_token = ''\n",
    "access_token_secret = ''\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Looping to download all info and store in a list instance ###\n",
    "tweet_json = []\n",
    "tweet_error = {}\n",
    "for tweet_id in twitter_archive_enhanced.tweet_id:\n",
    "    try:\n",
    "        tweet = api.get_status(tweet_id, tweet_mode='extended')\n",
    "        tweet_json.append(tweet._json)\n",
    "    except Exception as e:\n",
    "        tweet_error[tweet_id] = e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 343\n"
     ]
    }
   ],
   "source": [
    "### Re-download the error part ###\n",
    "tweet_error_2nd = {}\n",
    "for tweet_id in tweet_error.keys():\n",
    "    try:\n",
    "        tweet = api.get_status(tweet_id, tweet_mode='extended')\n",
    "        tweet_json.append(tweet._json)\n",
    "    except Exception as e:\n",
    "        tweet_error_2nd[tweet_id] = e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{704761120771465216: tweepy.error.TweepError(\"Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=60)\"),\n",
       " 775096608509886464: tweepy.error.TweepError([{'code': 144,\n",
       "                           'message': 'No status found with that ID.'}]),\n",
       " 802247111496568832: tweepy.error.TweepError([{'code': 144,\n",
       "                           'message': 'No status found with that ID.'}]),\n",
       " 827228250799742977: tweepy.error.TweepError([{'code': 144,\n",
       "                           'message': 'No status found with that ID.'}]),\n",
       " 837012587749474308: tweepy.error.TweepError([{'code': 144,\n",
       "                           'message': 'No status found with that ID.'}]),\n",
       " 842892208864923648: tweepy.error.TweepError([{'code': 144,\n",
       "                           'message': 'No status found with that ID.'}]),\n",
       " 845459076796616705: tweepy.error.TweepError([{'code': 144,\n",
       "                           'message': 'No status found with that ID.'}]),\n",
       " 861769973181624320: tweepy.error.TweepError([{'code': 144,\n",
       "                           'message': 'No status found with that ID.'}]),\n",
       " 866816280283807744: tweepy.error.TweepError([{'code': 144,\n",
       "                           'message': 'No status found with that ID.'}]),\n",
       " 869988702071779329: tweepy.error.TweepError([{'code': 144,\n",
       "                           'message': 'No status found with that ID.'}]),\n",
       " 873697596434513921: tweepy.error.TweepError([{'code': 144,\n",
       "                           'message': 'No status found with that ID.'}]),\n",
       " 888202515573088257: tweepy.error.TweepError([{'code': 144,\n",
       "                           'message': 'No status found with that ID.'}])}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_error_2nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "### From above, there are 11 tweet_id are unable to find corresponding info ###\n",
    "### Re-download the last one ###\n",
    "tweet = api.get_status('704761120771465216', tweet_mode='extended')\n",
    "tweet_json.append(tweet._json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Store result in txt file ###\n",
    "with open('tweet_json_YY.txt', 'w') as output:  \n",
    "    for i in range(len(tweet_json)):\n",
    "        json.dump(tweet_json[i], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import tweet_json.txt to pandas.DataFrame ###\n",
    "json_str = []\n",
    "with open('tweet_json.txt', encoding='utf-8') as json_file:\n",
    "    for i in range(2352):   # there are 2352 rows in txt file got from visual inspection\n",
    "        tweet = json_file.readline()\n",
    "        json_str.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform string read from txt to dic, and store in list to create DataFrame #\n",
    "json_list = []\n",
    "for i in range(len(json_str)):\n",
    "    json_list.append(json.loads(json_str[i]))\n",
    "\n",
    "tweet_json = pd.DataFrame(json_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2352 entries, 0 to 2351\n",
      "Data columns (total 31 columns):\n",
      "contributors                     0 non-null object\n",
      "coordinates                      0 non-null object\n",
      "created_at                       2352 non-null object\n",
      "display_text_range               2352 non-null object\n",
      "entities                         2352 non-null object\n",
      "extended_entities                2073 non-null object\n",
      "favorite_count                   2352 non-null int64\n",
      "favorited                        2352 non-null bool\n",
      "full_text                        2352 non-null object\n",
      "geo                              0 non-null object\n",
      "id                               2352 non-null int64\n",
      "id_str                           2352 non-null object\n",
      "in_reply_to_screen_name          78 non-null object\n",
      "in_reply_to_status_id            78 non-null float64\n",
      "in_reply_to_status_id_str        78 non-null object\n",
      "in_reply_to_user_id              78 non-null float64\n",
      "in_reply_to_user_id_str          78 non-null object\n",
      "is_quote_status                  2352 non-null bool\n",
      "lang                             2352 non-null object\n",
      "place                            1 non-null object\n",
      "possibly_sensitive               2211 non-null object\n",
      "possibly_sensitive_appealable    2211 non-null object\n",
      "quoted_status                    28 non-null object\n",
      "quoted_status_id                 29 non-null float64\n",
      "quoted_status_id_str             29 non-null object\n",
      "retweet_count                    2352 non-null int64\n",
      "retweeted                        2352 non-null bool\n",
      "retweeted_status                 177 non-null object\n",
      "source                           2352 non-null object\n",
      "truncated                        2352 non-null bool\n",
      "user                             2352 non-null object\n",
      "dtypes: bool(4), float64(3), int64(3), object(21)\n",
      "memory usage: 505.4+ KB\n"
     ]
    }
   ],
   "source": [
    "tweet_json.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Data Collection\n",
    "\n",
    "Corresponding to three targets,\n",
    "1. Existed file was loaded via `pandas.read_csv` from local path, storing as `twitter_archive_enhanced` dataframe\n",
    "2. Image recognition result was downloaded via `pandas.read_csv` from url, storing as `image_predictions` dataframe\n",
    "3. Tweet info downloaded via tweepy was stored in `tweet_json_YY.txt`, to be distinguishable from the provided `tweet_json.txt` . However, to be eaiser for project reivew, `tweet_json.txt` was still used to generate `tweet_json` dataframe for the rest of project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Assessing\n",
    "\n",
    "Accomplish at least 8 quality issues and 2 tidiness issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Accomplish at least 8 quality issues and 2 tidiness issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Storage and Visualization\n",
    "\n",
    "1. Store the processed data as `twitter_archive_master.csv`\n",
    "2. Illustrate at least 3 intuitions from data analysis and 1 visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sumamry Report\n",
    "\n",
    "1. 300-to-600-word report for internal assessment to complete project, about how the whole project was done, saved as `wrangle_report.pdf` \n",
    "2. ~250-word report for external demonstration like blog post, saved as `act_report.pdf` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
