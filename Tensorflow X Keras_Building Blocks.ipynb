{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow X Keras: Buiding Blocks (How to Play)\n",
    "\n",
    "This is a summary of the Keras basic building procedures, which is a guide of running a model with Tensorflow backend.\n",
    "\n",
    "**The whole procedure can be divided into four parts:**\n",
    "1. Create Model\n",
    "2. Compile Backward Propagation Setting \n",
    "3. Train Model\n",
    "4. Evaluate and Predict\n",
    "5. Callback for TensorBoard (Visualization)\n",
    "\n",
    "## 1. Create Model\n",
    "\n",
    "For any model, there are two ways to create:\n",
    "- [Functional API](https://keras.io/getting-started/functional-api-guide/) *--> define calculation between layers and assemble to a model*\n",
    "    - highly customized computation graph\n",
    "    - model is callable\n",
    "    - model can be easily reused as a block for other model\n",
    "- [Sequential Model API](https://keras.io/getting-started/sequential-model-guide/) *--> add layers upon model*\n",
    "    - fast and easy to create\n",
    "    - simple or standard computation graph\n",
    "    \n",
    "The shape of input need to be defined in 1st layer, and there is no sample size or batch size needed normally.  [Keras Doc](https://keras.io/getting-started/sequential-model-guide/#specifying-the-input-shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For Functional API                                          ### For Sequential Model API\n",
    "from keras.models import Model                                  from keras.models import Sequential\n",
    "from keras.layers import Input, Dense                           from keras.layers import Dense, Activation\n",
    "\n",
    "                                                                # Start a model instance\n",
    "                                                                model = Sequential()\n",
    "# Define input shape by returning a tensor\n",
    "inputs = Input(shape=(784,))\n",
    "\n",
    "# Define layers and its inputs\n",
    "# Use built-in functions or customized function returning x    # Top-up layers\n",
    "x = Dense(32, activation='relu')(inputs)                        model.add(Dense(32, input_shape=(784,)))  # Only define on 1st\n",
    "                                                                model.add(Activation('relu'))\n",
    "x = Dense(32, activation='relu')(x)                             model.add(Dense(32))\n",
    "                                                                model.add(Activation('relu'))\n",
    "predictions = Dense(10, activation='softmax')(x)                model.add(Dense(10))\n",
    "                                                                model.add(Activation('softmax'))\n",
    "# Creates a model gathering above\n",
    "model = Model(inputs=inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compile Backward Propagation Setting\n",
    "\n",
    "This section includes three parts in normal case:\n",
    "- **optimizer:** string or instance (created to customize setting)\n",
    "- **loss:** string or objective function \n",
    "- **metrics:** a list of string or customized metrics function\n",
    "\n",
    "If you are going to train a multi-input and multi-output model, the weights of different loss can be defined. [Keras Doc](https://keras.io/getting-started/functional-api-guide/#multi-input-and-multi-output-models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Default optimizer\n",
    "# For a multi-class classification problem\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# For a mean squared error regression problem\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mse')\n",
    "\n",
    "\n",
    "### Customized optimizer\n",
    "from keras import optimizers\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='mean_squared_error', optimizer=sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Model\n",
    "\n",
    "Define data, labels, epochs and batch_size for *model.fit*.\n",
    "\n",
    "**PS:** For deep learning, there is no necessary to perform *cross-validation*. Because it is designed to search best hyperparameters for tiny dataset, and trains multiple models with different folds of dataset avoiding overfitting. In DL era, data is large enough to avoid overfitting so dataset is only splitted into **train / validate / test set**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate and Predict\n",
    "\n",
    "For special case, batch_size can be added in to keep the evaluate process same as training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, \n",
    "                       y_test, \n",
    "                       batch_size=128)\n",
    "predict = model.predict(x_test,\n",
    "                        batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Callback for TensorBoard (Visualization)\n",
    "\n",
    "Create a callback instance as below and put into `model.fit(callbacks=<instance>)`.\n",
    "\n",
    "``` python\n",
    "keras.callbacks.TensorBoard(log_dir='./logs',\n",
    "                            histogram_freq=0, \n",
    "                            batch_size=32, \n",
    "                            write_graph=True, \n",
    "                            write_grads=False, \n",
    "                            write_images=False, \n",
    "                            embeddings_freq=0, \n",
    "                            embeddings_layer_names=None, \n",
    "                            embeddings_metadata=None)\n",
    "```\n",
    "\n",
    "Run TensorBoard with `tensorboard --logdir=/full_path_to_your_logs`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional: Visualize the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### List of model details\n",
    "model.summary()\n",
    "\n",
    "\n",
    "### Graphical demonstration using graphviz (export a file)\n",
    "from keras.utils import plot_model\n",
    "\n",
    "plot_model(model, to_file='model.png')\n",
    "\n",
    "\n",
    "### Graphical demonstration using inline plotting\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Example\n",
    "\n",
    "### Residual connection on a convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4b09ae1beb71>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# input tensor for a 3-channel 256x256 image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# 3x3 conv with 3 output channels (same as input channels)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, Input\n",
    "\n",
    "# input tensor for a 3-channel 256x256 image\n",
    "x = Input(shape=(256, 256, 3))\n",
    "# 3x3 conv with 3 output channels (same as input channels)\n",
    "y = Conv2D(3, (3, 3), padding='same')(x)\n",
    "# this returns x + y.\n",
    "z = keras.layers.add([x, y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Input\n",
    "\n",
    "input_img = Input(shape=(256, 256, 3))\n",
    "\n",
    "tower_1 = Conv2D(64, (1, 1), padding='same', activation='relu')(input_img)\n",
    "tower_1 = Conv2D(64, (3, 3), padding='same', activation='relu')(tower_1)\n",
    "\n",
    "tower_2 = Conv2D(64, (1, 1), padding='same', activation='relu')(input_img)\n",
    "tower_2 = Conv2D(64, (5, 5), padding='same', activation='relu')(tower_2)\n",
    "\n",
    "tower_3 = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(input_img)\n",
    "tower_3 = Conv2D(64, (1, 1), padding='same', activation='relu')(tower_3)\n",
    "\n",
    "output = keras.layers.concatenate([tower_1, tower_2, tower_3], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron (MLP) for multi-class softmax classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Generate dummy data\n",
    "import numpy as np\n",
    "x_train = np.random.random((1000, 20))\n",
    "y_train = keras.utils.to_categorical(np.random.randint(10, size=(1000, 1)), num_classes=10)\n",
    "x_test = np.random.random((100, 20))\n",
    "y_test = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\n",
    "\n",
    "model = Sequential()\n",
    "# Dense(64) is a fully-connected layer with 64 hidden units.\n",
    "# in the first layer, you must specify the expected input data shape:\n",
    "# here, 20-dimensional vectors.\n",
    "model.add(Dense(64, activation='relu', input_dim=20))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128)\n",
    "score = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG-like convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Generate dummy data\n",
    "x_train = np.random.random((100, 100, 100, 3))\n",
    "y_train = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\n",
    "x_test = np.random.random((20, 100, 100, 3))\n",
    "y_test = keras.utils.to_categorical(np.random.randint(10, size=(20, 1)), num_classes=10)\n",
    "\n",
    "model = Sequential()\n",
    "# input: 100x100 images with 3 channels -> (100, 100, 3) tensors.\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=10)\n",
    "score = model.evaluate(x_test, y_test, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
